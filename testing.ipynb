{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as ag\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#use .clone() to copy data and not get affected by backprop\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Variables during the backward pass.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Variables during the backward pass.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(100):\n",
    "    # Forward pass: compute predicted y using operations on Variables; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Variables.\n",
    "    # Now loss is a Variable of shape (1,) and loss.data is a Tensor of shape\n",
    "    # (1,); loss.data[0] is a scalar value holding the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent; w1.data and w2.data are Tensors,\n",
    "    # w1.grad and w2.grad are Variables and w1.grad.data and w2.grad.data are\n",
    "    # Tensors.\n",
    "    r = w1.data.clone()\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "print r\n",
    "print w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ag.Variable(torch.Tensor([7]), requires_grad=True)\n",
    "z_pred = x*4\n",
    "z = ag.Variable(torch.Tensor([29]))\n",
    "loss = nn.MSELoss()\n",
    "l = loss(z_pred,z)\n",
    "l.backward()\n",
    "print x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    y = x**2\n",
    "    print y.requires_grad\n",
    "    return y\n",
    "\n",
    "x = ag.Variable(torch.Tensor([7]), requires_grad=True)\n",
    "#c = ag.Variable(torch.Tensor([6]), requires_grad=True)\n",
    "z = ag.Variable(torch.Tensor([100]))\n",
    "\n",
    "v1 = f1(x)\n",
    "\n",
    "print v1\n",
    "y=x*2\n",
    "z_pred = f1(y)*4\n",
    "#v2 = f1(x)\n",
    "#print v1,v2\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "l = loss(z_pred,z)\n",
    "l.backward()\n",
    "print x.grad.data\n",
    "print z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a subset of friends dataset to experiment the pipeline\n",
    "fr = open('Friends-dialogues.txt','r')\n",
    "fw = open('testd.txt','w')\n",
    "c = 0\n",
    "for l in fr:\n",
    "    c+=1\n",
    "    if c>1000:\n",
    "        break\n",
    "    fw.write(l)\n",
    "print c\n",
    "fw.close()\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making counter to pass to vocab file\n",
    "from collections import Counter\n",
    "\n",
    "f = open('Friends-dialogues.txt','r')\n",
    "vc = Counter()\n",
    "for l in f:\n",
    "    vc.update(Counter(l.split()))\n",
    "#print vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from /home/rohith/Documents/NLP/Dialogue/glove.840B.300d.pt\n",
      "0:00:02.161140\n"
     ]
    }
   ],
   "source": [
    "#creating the vocab object\n",
    "from datetime import datetime\n",
    "import vocab\n",
    "st = datetime.now()\n",
    "vcb = vocab.Vocab(vc, wv_type = \"glove.840B\",min_freq=4,specials = [\"EOS\",\"SOS\"])\n",
    "print datetime.now()-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(vcb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(vc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = vcb.stoi['rod']\n",
    "t2 = vcb.vectors[t1]\n",
    "print t1,t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from /home/rohith/Documents/NLP/Dialogue/glove.840B.300d.pt\n"
     ]
    }
   ],
   "source": [
    "reload(framework)\n",
    "import framework as fw\n",
    "eg = fw.EmbedGlove('Friends-dialogues.txt',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.1873  0.4060 -0.5117 -0.5548  0.0397  0.1289  0.4514 -0.5915  0.1559  1.5137\n",
      "-0.0818  0.9505 -0.1963  0.3232 -0.1147  0.7249  0.1999 -0.4187 -0.2152  2.2864\n",
      "-0.5332 -0.2498 -0.1741 -0.4171 -0.2133 -0.0225  0.5537 -0.0043  0.0927  1.8810\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.8702  0.0507  0.1521 -0.1918  0.1118  0.1213 -0.2721  1.6203 -0.2488  0.1406\n",
      "-0.3711  0.2062 -0.3483 -0.2462  0.1968 -0.0793 -0.3658  1.1856 -0.0036  0.5756\n",
      "-0.2009 -0.1683  0.1942  0.4859  0.1312 -0.0854 -0.3066  0.6197 -0.0976  0.2591\n",
      "\n",
      "Columns 20 to 29 \n",
      " 0.3310 -0.0181  0.1524 -0.2694 -0.2783 -0.0521 -0.4815 -0.5184  0.0863  0.0308\n",
      "-0.2336 -0.4572  0.1861  0.5361 -0.0551  0.2624 -0.0190 -0.0534  0.9933 -0.0463\n",
      " 0.0424 -0.1762 -0.6568  0.0483 -0.1065 -0.0099  0.1474  0.0025  0.1878  0.5954\n",
      "\n",
      "Columns 30 to 39 \n",
      "-0.2125 -0.1138 -0.2238  0.1826 -0.3454  0.0826  0.1002 -0.0795 -0.8172  0.0066\n",
      "-0.5834  0.2483  0.2363  0.3674 -0.4109 -0.0242 -0.3845  0.3311 -0.2528 -0.0211\n",
      "-0.2276  0.3172  0.0656  0.3834  0.4333  0.1955 -0.4028 -0.4735 -0.5498  0.5741\n",
      "\n",
      "Columns 40 to 49 \n",
      " 0.0801 -0.3998 -0.0631  0.3226 -0.0316  0.4306 -0.2727 -0.0760  0.1029 -0.0887\n",
      "-0.2903 -0.3119 -0.3785  0.7986  0.3376  0.6046  0.2111  0.0172  0.1644 -0.3415\n",
      "-0.0545 -0.2873 -0.3823  0.0147 -0.0206 -0.7534  0.0810  0.1247 -0.1538  0.0828\n",
      "\n",
      "Columns 50 to 59 \n",
      "-0.2909 -0.0472  0.0460 -0.0178  0.0650  0.0885 -0.3157 -0.5852  0.2229 -0.0528\n",
      " 0.3201  0.3474 -0.6094  0.2885  0.4793  0.5848 -0.7508 -0.4440  0.0065 -0.1075\n",
      "-0.2541  0.1726 -0.3631  0.2626 -0.0760 -0.1923 -0.1419  0.0681 -0.0780 -0.0231\n",
      "\n",
      "Columns 60 to 69 \n",
      "-0.5598 -0.3958 -0.0798 -0.0109 -0.0417 -0.5558  0.0887  0.1371 -0.0030 -0.0263\n",
      " 0.0919 -1.1566 -0.0759 -0.1732 -0.6590 -0.7684  0.6986 -0.0393  0.3576  0.5652\n",
      "-0.3365 -0.4058 -0.2998 -0.1415  0.2012 -0.4411 -0.2881 -0.2972 -0.0643 -0.3672\n",
      "\n",
      "Columns 70 to 79 \n",
      " 0.0773  0.3920  0.3451 -0.0801  0.3345  0.2706 -0.0245  0.0726 -0.1812  0.2369\n",
      " 0.0202 -0.4952 -0.1935 -0.1659  0.8382  0.5043  0.5301  0.2246 -0.3842  0.6296\n",
      "-0.2722  0.2781 -0.1150 -0.4867 -0.3512  0.4760  0.0500  0.1022 -0.1405  0.4312\n",
      "\n",
      "Columns 80 to 89 \n",
      " 0.3998  0.4501  0.0272  0.2740  0.1479 -0.0058  0.9591 -1.0129  0.2070  0.1824\n",
      " 0.1962  0.0511  0.0859 -0.3147  0.3412 -0.1953  0.5740 -0.8924  0.6083 -0.0213\n",
      " 0.0006  0.3017  0.1763  0.2945  0.4538 -0.7986  0.9021 -1.1657 -0.3566 -0.3503\n",
      "\n",
      "Columns 90 to 99 \n",
      "-0.2523 -0.2626 -0.3480 -0.0241  0.4447  0.0592  0.4556  0.1970 -0.4833  0.0895\n",
      " 0.2052 -0.3136 -0.8163  0.2949  0.3400  0.2338  0.4766  0.0645 -0.1714 -0.1068\n",
      "-0.1962 -0.1802 -0.4584  0.1116  0.2971 -0.1539  0.0079 -0.4061 -0.4628 -0.2776\n",
      "\n",
      "Columns 100 to 109 \n",
      "-0.2237 -0.1565  0.2158  0.1167  0.0820 -0.8073  0.2390 -0.5130 -0.3389 -0.3150\n",
      "-0.0112 -0.0586 -0.2004 -0.2462  0.3630  0.5652 -0.5162 -0.8099  0.0277  0.1014\n",
      "-0.1174 -0.4564  0.0199  0.6020  0.0408 -0.6691 -0.5302  0.0227 -0.3107 -0.4342\n",
      "\n",
      "Columns 110 to 119 \n",
      "-0.1727 -0.6702  0.2710 -0.4324  0.0431  0.0212  0.0133 -0.0639 -0.2496 -0.2494\n",
      "-0.2474 -0.3034  0.3037 -0.4230  0.5655 -0.1167 -0.3120 -0.5697 -0.0808 -0.0922\n",
      " 0.0211  0.0725  0.0915 -0.2963  0.2414  0.5224  0.3663  0.1480 -0.0305  0.0433\n",
      "\n",
      "Columns 120 to 129 \n",
      " 0.3481 -0.0713  0.2338 -0.0954  0.5249  0.6817 -0.1021 -0.1491 -0.0757  0.1725\n",
      " 0.1181 -0.3799  0.4198 -0.2639  0.5851 -0.0365 -0.0305 -0.1405 -0.4937  0.0519\n",
      "-0.1034 -0.2409  0.1936  0.5319 -0.0283 -0.1557  0.0320 -0.5179 -0.2097  0.0123\n",
      "\n",
      "Columns 130 to 139 \n",
      " 0.2544  0.1576 -0.5913  0.2430  0.6396 -0.0933 -0.2791 -0.0663 -0.0672 -0.4093\n",
      " 0.1048 -0.4489 -0.6694 -0.0898  0.1384 -0.6979 -0.4308  0.2385 -0.1325  0.2140\n",
      " 0.0022 -0.2572 -0.2020 -0.6246 -0.1423 -0.2096 -0.0304  0.1105 -0.4135  0.0631\n",
      "\n",
      "Columns 140 to 149 \n",
      "-3.0300  0.1825  0.2011  0.0606 -0.2477  0.0553 -0.4911  0.3154 -0.3423 -0.6377\n",
      "-1.3762  0.1181  0.1611  0.1253  0.0543  0.5488 -0.3709 -0.1010 -0.0724 -0.6655\n",
      "-3.1873  0.3478  0.1435  0.1000 -0.4794  0.0822  0.2352 -0.1550 -0.3808 -0.8361\n",
      "\n",
      "Columns 150 to 159 \n",
      "-0.3613 -0.0590  0.1551  0.0446  0.2357 -0.1709 -0.2275 -0.0232  0.2387  0.0282\n",
      "-0.3403  0.0322 -0.0763  0.3755 -0.4159  0.2268  0.3460 -0.3343 -0.5374  0.0944\n",
      "-0.3152 -0.5575  0.0069  0.1008  0.2822  0.3266 -0.1582 -0.7042  0.1355  0.2088\n",
      "\n",
      "Columns 160 to 169 \n",
      " 0.4297 -0.1246 -0.0370  0.2006 -0.3140 -0.0853 -0.3350 -0.0970 -0.1439  0.1115\n",
      "-0.0171 -0.2616  0.2780 -0.0655  0.0736  0.2578 -0.0357 -0.1428 -0.2054 -0.1876\n",
      " 0.5734 -0.2733 -0.1290  0.2268  0.3115  0.1113 -0.2543  0.4948 -0.7404  0.0198\n",
      "\n",
      "Columns 170 to 179 \n",
      "-0.4523 -0.2422 -0.1824 -0.6729  0.0219 -0.0548 -0.4651  0.4777 -0.2475 -0.1579\n",
      "-0.5561 -0.3227  0.2959 -0.3977 -0.0250 -0.0482 -0.3434 -0.1769  0.2587  0.6849\n",
      "-0.3487 -0.0437  0.9215 -0.4637  0.0143  0.1906  0.0350  0.3536 -0.2037 -0.8830\n",
      "\n",
      "Columns 180 to 189 \n",
      " 0.1182  0.0569 -0.4915  0.1550  0.0164  0.0417 -0.3499 -0.1598  0.3970  0.2296\n",
      "-0.3305 -0.0576 -0.3374 -0.1256 -0.2937  0.1914  0.0539 -0.0278  0.1951  0.1183\n",
      " 0.3103  0.1312 -0.6785 -0.1459 -0.4566 -0.0689 -0.0710  0.1001  0.1632  0.0692\n",
      "\n",
      "Columns 190 to 199 \n",
      " 0.2469  0.0196 -0.2880 -0.6998  0.3274  0.1083  0.2494 -0.7865 -0.0614 -0.3736\n",
      "-0.5804  0.3568 -0.6148 -0.5182  0.1487  0.8745 -0.2313  0.4047 -0.0786 -0.2015\n",
      "-0.3320 -0.3332 -0.7153  0.3826  0.1469 -0.0494 -0.1199 -0.5106  0.0344  0.3221\n",
      "\n",
      "Columns 200 to 209 \n",
      "-0.1160 -0.2495  0.1016  0.0340  0.1565  0.2134 -0.1109 -0.0058  0.1787 -0.1013\n",
      " 0.4388 -0.1050  0.0665  0.1582  0.3269  0.0777 -0.1377 -0.2831  0.0563  0.0307\n",
      "-0.3841  0.4309  0.0685  0.3327  0.3113  0.1031 -0.1200  0.2460  0.3706 -0.3563\n",
      "\n",
      "Columns 210 to 219 \n",
      "-0.0169  0.3000 -0.3412 -0.0324  0.0425  0.1185 -0.1834 -0.6287 -0.2802  0.4235\n",
      "-0.1683 -0.2482  0.1601 -0.2765  0.2625 -0.0071 -0.3471  0.2975 -0.3521 -0.0335\n",
      "-0.2691 -0.2149  0.5532  0.5287 -0.1351 -0.6329  0.1602 -0.4513 -0.3219  0.1666\n",
      "\n",
      "Columns 220 to 229 \n",
      " 0.1128  0.0012  0.1571 -0.3632 -0.4925  0.1165  0.2402  0.1771  0.0687 -0.4414\n",
      " 0.3286 -0.0419  0.3740  0.2558  0.1634 -0.0753  0.3468  0.1815 -0.3850 -0.3758\n",
      "-0.0431 -0.1635 -0.1206 -0.1722  0.1308  0.2888 -0.0109  0.4982 -0.4743 -0.2240\n",
      "\n",
      "Columns 230 to 239 \n",
      "-0.2988 -0.0121  0.2833  0.1067 -0.1886 -0.4135 -0.3409  0.0472 -0.3831  0.4357\n",
      "-0.0906  0.1912 -0.3093  0.1318 -0.2788 -0.5698 -0.6629 -0.3095 -0.2000  0.4937\n",
      "-0.2430  0.1757 -0.2467  0.0676  0.1072 -0.2449  0.0524  0.0824 -0.2337 -0.1334\n",
      "\n",
      "Columns 240 to 249 \n",
      " 0.2450  0.2734 -0.0730  0.4251 -0.0325 -0.3521  0.4569  0.1943 -0.1523  0.4268\n",
      " 0.3472  0.0237  0.1035  0.2853 -0.4039 -0.4065 -0.0393 -0.1462  0.3438  0.8550\n",
      "-0.0551  0.2293  0.1177 -0.1269  0.1177 -0.0072  0.0330 -0.1314 -0.0321 -0.0142\n",
      "\n",
      "Columns 250 to 259 \n",
      " 0.2880 -0.5597 -0.1303  0.0898  0.4261 -0.1963 -0.0720 -0.0802 -0.3043 -0.4619\n",
      "-0.0744  0.1585 -0.0732 -0.0727  0.6423 -0.2316  0.0074 -0.0921  0.0635 -0.0747\n",
      " 0.3292 -0.2931  0.1092 -0.1323  0.0963  0.6457 -0.0623  0.2997 -0.4584  0.1132\n",
      "\n",
      "Columns 260 to 269 \n",
      " 0.2818 -0.0999  0.3510  0.1612 -0.0365 -0.3674 -0.0198  0.3213  0.1748  0.2517\n",
      " 0.3470  0.4223  0.4824  0.1778 -0.1415 -0.1844 -0.2447  0.0844 -0.0011  0.1066\n",
      " 0.1540  0.2385 -0.0323  0.0822 -0.3564 -0.2162 -0.2032  0.2401  0.2663  0.5865\n",
      "\n",
      "Columns 270 to 279 \n",
      "-0.0076 -0.0938 -0.3785  0.4372  0.2129  0.2510 -0.1961 -0.2887 -0.0057  0.4279\n",
      "-0.2515 -0.1709 -0.6851 -0.1290  0.0840  0.1530  0.1115 -0.4258 -0.3458  0.7903\n",
      "-0.0719  0.0462 -0.2780  0.3552 -0.0705  0.3328  0.3715 -0.3192  0.0044 -0.4489\n",
      "\n",
      "Columns 280 to 289 \n",
      " 0.2062 -0.0377 -0.1220 -0.0793 -0.1029  0.0106  0.4988  0.2538  0.1553  0.0018\n",
      " 0.2590 -0.5106  0.0799 -0.0250  0.1845  0.0267  0.2236 -0.1597  0.1014  0.8069\n",
      " 0.2866 -0.4010 -0.1934 -0.3164 -0.1029  0.0551  0.2179 -0.1231  0.1606 -0.0548\n",
      "\n",
      "Columns 290 to 299 \n",
      " 0.1163  0.0793 -0.3914 -0.3248  0.6345 -0.1891  0.0540  0.1649  0.1876  0.5387\n",
      " 0.0638  0.2234 -0.2617 -0.4617  0.0377 -0.0775 -0.1716 -0.1518 -0.2386  0.4129\n",
      "-0.1593  0.1402 -0.5370 -0.0307  0.0740  0.2295  0.3509  0.7382  0.0384 -0.2981\n",
      "[torch.FloatTensor of size 3x300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print eg(\"I am god\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a77b7ffd8>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "reload(framework)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = fw.EncoderLSTM(300,200,eg,0.1,n_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = fw.DecoderLSTM(300,200,20,eg,n_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.0882 -0.0149 -0.1558  0.0466  0.0792  0.0284  0.0657 -0.1425  0.1002\n",
      "\n",
      "Columns 9 to 17 \n",
      "  -0.0397  0.1045 -0.0106 -0.1245 -0.0362 -0.0271 -0.0676 -0.0134  0.0652\n",
      "\n",
      "Columns 18 to 26 \n",
      "  -0.0453  0.0008 -0.0618 -0.0106  0.0219  0.0125 -0.0703 -0.0439 -0.0490\n",
      "\n",
      "Columns 27 to 35 \n",
      "   0.0321 -0.0073 -0.0613  0.0514 -0.1238 -0.0355  0.0931  0.0256  0.0121\n",
      "\n",
      "Columns 36 to 44 \n",
      "   0.0388 -0.0762  0.1072 -0.0099  0.0784  0.0022  0.0380  0.0893 -0.0474\n",
      "\n",
      "Columns 45 to 53 \n",
      "  -0.0697 -0.1635 -0.0633 -0.0722  0.0209  0.0860  0.0558  0.0350  0.0022\n",
      "\n",
      "Columns 54 to 62 \n",
      "   0.0023 -0.1062  0.0680  0.0511  0.0311  0.0193 -0.0154  0.0751 -0.0655\n",
      "\n",
      "Columns 63 to 71 \n",
      "   0.0056  0.0923 -0.0695 -0.0098  0.0307 -0.0090 -0.0283 -0.0630  0.1012\n",
      "\n",
      "Columns 72 to 80 \n",
      "  -0.1018  0.0006 -0.0043  0.0120 -0.0495  0.0247 -0.0120 -0.0635 -0.0288\n",
      "\n",
      "Columns 81 to 89 \n",
      "   0.0023  0.0613 -0.0612  0.0420  0.0120 -0.0255  0.0390  0.0626 -0.0739\n",
      "\n",
      "Columns 90 to 98 \n",
      "  -0.0484 -0.0854  0.0420  0.0347 -0.0368  0.0067 -0.0326 -0.0689 -0.0043\n",
      "\n",
      "Columns 99 to 107 \n",
      "   0.0229  0.0723 -0.0537  0.0947 -0.0125  0.0260  0.0177  0.0734 -0.0253\n",
      "\n",
      "Columns 108 to 116 \n",
      "   0.0079 -0.0070  0.0235 -0.0014 -0.0079 -0.0159  0.0317  0.0182 -0.0033\n",
      "\n",
      "Columns 117 to 125 \n",
      "  -0.0635  0.0884  0.0452  0.1012  0.0121 -0.0154  0.0398 -0.0217  0.1043\n",
      "\n",
      "Columns 126 to 134 \n",
      "   0.0662  0.0615 -0.1154 -0.0569  0.0348 -0.0217  0.1055  0.1066 -0.0682\n",
      "\n",
      "Columns 135 to 143 \n",
      "   0.0681  0.0549 -0.0459  0.0549  0.0234 -0.0342 -0.0523 -0.0867  0.0058\n",
      "\n",
      "Columns 144 to 152 \n",
      "  -0.0020 -0.0319  0.0996 -0.0484 -0.0296  0.0325 -0.0786  0.0340  0.0880\n",
      "\n",
      "Columns 153 to 161 \n",
      "   0.0474  0.0206  0.0033 -0.1556  0.0879  0.0530 -0.0243 -0.0502  0.0059\n",
      "\n",
      "Columns 162 to 170 \n",
      "  -0.0331 -0.0301 -0.0081  0.0594  0.0903  0.0615  0.0949  0.0604  0.1360\n",
      "\n",
      "Columns 171 to 179 \n",
      "  -0.0629 -0.0249 -0.0960 -0.0151  0.0847 -0.0004  0.0178  0.0101 -0.0627\n",
      "\n",
      "Columns 180 to 188 \n",
      "  -0.0253 -0.0157  0.0391  0.0061 -0.0147  0.0584 -0.0010 -0.1400 -0.0813\n",
      "\n",
      "Columns 189 to 197 \n",
      "  -0.0414  0.0692  0.0046 -0.0318 -0.0158 -0.0818 -0.0184  0.0881 -0.0385\n",
      "\n",
      "Columns 198 to 199 \n",
      "   0.0542  0.0787\n",
      "\n",
      "( 1 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.0848  0.0061 -0.1130  0.0267  0.0483  0.0735  0.0450 -0.0466  0.1188\n",
      "\n",
      "Columns 9 to 17 \n",
      "  -0.0445  0.1176  0.0041 -0.0932 -0.0987 -0.0595 -0.1061 -0.1036  0.0146\n",
      "\n",
      "Columns 18 to 26 \n",
      "  -0.0863  0.0239 -0.1129 -0.1461 -0.0386  0.0175 -0.0732 -0.0952  0.0368\n",
      "\n",
      "Columns 27 to 35 \n",
      "   0.0382 -0.0787 -0.0922  0.0900 -0.0848  0.0760  0.0812 -0.0335  0.0807\n",
      "\n",
      "Columns 36 to 44 \n",
      "   0.0140 -0.0094  0.1194  0.0529  0.1163 -0.0946  0.0045  0.1920 -0.0324\n",
      "\n",
      "Columns 45 to 53 \n",
      "  -0.0503 -0.1705 -0.0378 -0.1173  0.0488  0.0584 -0.0094  0.0541 -0.0523\n",
      "\n",
      "Columns 54 to 62 \n",
      "  -0.0676 -0.1561  0.0682  0.0387  0.0141 -0.0201 -0.0490  0.0703 -0.0545\n",
      "\n",
      "Columns 63 to 71 \n",
      "  -0.0244 -0.0012 -0.0930 -0.0101  0.0663 -0.0380 -0.0546  0.0420  0.1327\n",
      "\n",
      "Columns 72 to 80 \n",
      "  -0.0401 -0.0574 -0.0268 -0.0697 -0.1799  0.0369 -0.0682 -0.1168 -0.0856\n",
      "\n",
      "Columns 81 to 89 \n",
      "  -0.0615  0.0876 -0.0138  0.0469  0.0700 -0.0440  0.0863  0.0681 -0.0844\n",
      "\n",
      "Columns 90 to 98 \n",
      "  -0.0899 -0.0577  0.1380  0.0327 -0.0603  0.0474  0.0227 -0.0986  0.0125\n",
      "\n",
      "Columns 99 to 107 \n",
      "  -0.0159  0.1751 -0.1420  0.0130 -0.0283 -0.0063  0.0201  0.0649  0.0717\n",
      "\n",
      "Columns 108 to 116 \n",
      "   0.0398 -0.0413  0.0996 -0.0435 -0.0396 -0.0589 -0.0209  0.0164  0.0527\n",
      "\n",
      "Columns 117 to 125 \n",
      "  -0.0568  0.0016 -0.0544  0.0585  0.0027 -0.0191  0.0024 -0.1150  0.1278\n",
      "\n",
      "Columns 126 to 134 \n",
      "  -0.0025  0.1544 -0.0456  0.0713 -0.0018 -0.0988  0.0766  0.1239 -0.0975\n",
      "\n",
      "Columns 135 to 143 \n",
      "  -0.0231  0.1164 -0.0192  0.0971  0.0365 -0.0491 -0.0817 -0.1865 -0.0427\n",
      "\n",
      "Columns 144 to 152 \n",
      "   0.0099  0.0142  0.1395 -0.1126 -0.0623  0.0438 -0.1058 -0.0181  0.0660\n",
      "\n",
      "Columns 153 to 161 \n",
      "   0.0421  0.0722 -0.0091 -0.1326  0.1192  0.0766 -0.1437 -0.1172  0.0283\n",
      "\n",
      "Columns 162 to 170 \n",
      "  -0.0827 -0.0489 -0.0342  0.0967  0.1016  0.0371  0.0979  0.0512  0.1359\n",
      "\n",
      "Columns 171 to 179 \n",
      "   0.0447 -0.0444 -0.0973  0.0241  0.0558 -0.0272 -0.0930  0.0153 -0.1265\n",
      "\n",
      "Columns 180 to 188 \n",
      "  -0.1323 -0.0577  0.0390 -0.0146 -0.0756  0.0344  0.0052 -0.1393 -0.0938\n",
      "\n",
      "Columns 189 to 197 \n",
      "  -0.0484  0.1893 -0.0104 -0.0182 -0.0034 -0.1646 -0.1196  0.1865 -0.0954\n",
      "\n",
      "Columns 198 to 199 \n",
      "  -0.0221  0.0679\n",
      "\n",
      "( 2 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.0593  0.0234 -0.1483  0.0775  0.0425  0.0803  0.0840 -0.0572  0.0414\n",
      "\n",
      "Columns 9 to 17 \n",
      "  -0.0366  0.0790  0.0331 -0.0283 -0.0514 -0.0133 -0.0991  0.0054 -0.0500\n",
      "\n",
      "Columns 18 to 26 \n",
      "  -0.1298  0.0434  0.0190 -0.0963 -0.0022  0.0265 -0.0209 -0.1132  0.0563\n",
      "\n",
      "Columns 27 to 35 \n",
      "   0.1013 -0.0811 -0.0030  0.0748 -0.1072  0.1389  0.0591 -0.0144  0.0686\n",
      "\n",
      "Columns 36 to 44 \n",
      "   0.0360 -0.0187  0.1392  0.0447  0.0084 -0.0732  0.0131  0.1597  0.0119\n",
      "\n",
      "Columns 45 to 53 \n",
      "  -0.0467 -0.2046  0.0071 -0.0599  0.0937  0.0827  0.0042  0.0668 -0.1449\n",
      "\n",
      "Columns 54 to 62 \n",
      "  -0.0649 -0.0670  0.0557 -0.0174  0.0108  0.1182 -0.0203  0.0763 -0.0785\n",
      "\n",
      "Columns 63 to 71 \n",
      "   0.0010  0.0700 -0.0775 -0.0356  0.0355 -0.0911 -0.0852  0.0099  0.1458\n",
      "\n",
      "Columns 72 to 80 \n",
      "  -0.0005  0.0086  0.0077 -0.0004 -0.0940  0.0504 -0.0669 -0.0764 -0.0868\n",
      "\n",
      "Columns 81 to 89 \n",
      "  -0.0436  0.0583  0.0477  0.0345  0.0828 -0.1093  0.0807  0.0965 -0.0345\n",
      "\n",
      "Columns 90 to 98 \n",
      "  -0.0841 -0.0635  0.1438 -0.0991 -0.1204  0.0551 -0.0522 -0.0428  0.0301\n",
      "\n",
      "Columns 99 to 107 \n",
      "   0.0447  0.1390 -0.1214  0.0339 -0.0049 -0.0097  0.0264  0.1258  0.0992\n",
      "\n",
      "Columns 108 to 116 \n",
      "   0.0139 -0.1115  0.0430  0.0029 -0.1024 -0.0726  0.0637  0.0616  0.0680\n",
      "\n",
      "Columns 117 to 125 \n",
      "  -0.0542  0.0881 -0.0616  0.0922 -0.0115  0.0012 -0.0346 -0.0182  0.0971\n",
      "\n",
      "Columns 126 to 134 \n",
      "  -0.0330  0.1460 -0.0706  0.0728  0.0575  0.0105  0.0856  0.1271 -0.0630\n",
      "\n",
      "Columns 135 to 143 \n",
      "   0.0988  0.1076 -0.0286  0.1054 -0.0342 -0.0627 -0.0627 -0.1660 -0.0083\n",
      "\n",
      "Columns 144 to 152 \n",
      "   0.0801  0.0026  0.1419 -0.1529 -0.0497  0.0230 -0.0780 -0.0768  0.0812\n",
      "\n",
      "Columns 153 to 161 \n",
      "   0.0427  0.0987 -0.0511 -0.1259  0.0565  0.0702 -0.0362 -0.1481 -0.0148\n",
      "\n",
      "Columns 162 to 170 \n",
      "  -0.0712  0.0183 -0.0728  0.0686  0.0478  0.0640  0.0156  0.0087  0.1576\n",
      "\n",
      "Columns 171 to 179 \n",
      "   0.0082  0.0044 -0.0769 -0.0644  0.1301 -0.0605 -0.0936  0.0028 -0.0700\n",
      "\n",
      "Columns 180 to 188 \n",
      "  -0.1065  0.0240  0.0425 -0.0497 -0.0719  0.0053 -0.0073 -0.1221 -0.0328\n",
      "\n",
      "Columns 189 to 197 \n",
      "  -0.0546  0.1644 -0.0009 -0.0927  0.0114 -0.0963 -0.0794  0.1560 -0.1392\n",
      "\n",
      "Columns 198 to 199 \n",
      "  -0.0091  0.0784\n",
      "\n",
      "( 3 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.1369 -0.0737 -0.1443 -0.0009  0.1188  0.1513  0.1441 -0.1191  0.1457\n",
      "\n",
      "Columns 9 to 17 \n",
      "   0.0293  0.1555 -0.0457 -0.0441  0.0161 -0.0443 -0.0954 -0.0741 -0.0150\n",
      "\n",
      "Columns 18 to 26 \n",
      "  -0.1368  0.0253 -0.0008  0.0034 -0.0306  0.1742 -0.0878 -0.0790  0.1096\n",
      "\n",
      "Columns 27 to 35 \n",
      "   0.0604 -0.0471  0.0125  0.0909 -0.1704  0.0744  0.0633  0.0279  0.1041\n",
      "\n",
      "Columns 36 to 44 \n",
      "  -0.0093 -0.0038  0.1917 -0.0720 -0.0066  0.0160 -0.0302  0.1214 -0.0099\n",
      "\n",
      "Columns 45 to 53 \n",
      "  -0.0342 -0.2006  0.0172 -0.1136  0.0168  0.0332  0.0253 -0.0583 -0.0906\n",
      "\n",
      "Columns 54 to 62 \n",
      "  -0.1308 -0.1953  0.0473  0.0006  0.0419  0.0920 -0.1270  0.1025 -0.0355\n",
      "\n",
      "Columns 63 to 71 \n",
      "   0.0518  0.0402 -0.0915 -0.0683  0.0588 -0.1361 -0.0062  0.0141  0.0779\n",
      "\n",
      "Columns 72 to 80 \n",
      "  -0.0151  0.0443 -0.0793  0.0160 -0.0772  0.0332  0.0087 -0.1222 -0.1206\n",
      "\n",
      "Columns 81 to 89 \n",
      "  -0.0414 -0.0015  0.1027  0.0660  0.1302 -0.1394  0.0925  0.1105  0.0417\n",
      "\n",
      "Columns 90 to 98 \n",
      "  -0.0882 -0.0574  0.0797 -0.0703 -0.0342  0.0225 -0.1635  0.0391  0.0628\n",
      "\n",
      "Columns 99 to 107 \n",
      "   0.0851  0.0355 -0.1953  0.1074 -0.0582  0.0677 -0.0410  0.1059 -0.0216\n",
      "\n",
      "Columns 108 to 116 \n",
      "   0.0069 -0.0808  0.0310 -0.0822 -0.0418 -0.1623  0.0283  0.0342  0.1266\n",
      "\n",
      "Columns 117 to 125 \n",
      "  -0.0890  0.1920 -0.1196  0.1268 -0.0202  0.0154 -0.0116  0.0650  0.1640\n",
      "\n",
      "Columns 126 to 134 \n",
      "   0.0173  0.1733 -0.1557  0.1210  0.1138  0.0241  0.0906  0.1229 -0.0510\n",
      "\n",
      "Columns 135 to 143 \n",
      "   0.0641  0.1251  0.0103  0.0902  0.0644 -0.1042  0.0062 -0.0292  0.1050\n",
      "\n",
      "Columns 144 to 152 \n",
      "   0.1629 -0.0637  0.1889 -0.0590 -0.0082  0.0946 -0.0191  0.0269  0.1416\n",
      "\n",
      "Columns 153 to 161 \n",
      "   0.0965  0.0694 -0.0506 -0.1876  0.0356  0.0525 -0.0401 -0.1518  0.0452\n",
      "\n",
      "Columns 162 to 170 \n",
      "  -0.0967 -0.0638 -0.0985  0.0046  0.0450  0.0446 -0.0012  0.0272  0.2311\n",
      "\n",
      "Columns 171 to 179 \n",
      "  -0.0174 -0.0066 -0.0114 -0.0010  0.0656 -0.0749 -0.1999 -0.0567 -0.0161\n",
      "\n",
      "Columns 180 to 188 \n",
      "  -0.1335 -0.0127  0.1558 -0.0302  0.0301  0.0557 -0.0366 -0.1261 -0.0931\n",
      "\n",
      "Columns 189 to 197 \n",
      "  -0.0966  0.0900  0.0584 -0.0180 -0.0306 -0.0593 -0.0818  0.1385 -0.1205\n",
      "\n",
      "Columns 198 to 199 \n",
      "  -0.0764  0.1705\n",
      "[torch.FloatTensor of size 4x1x200]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out,h = ls(\"I am good god\")\n",
    "print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "ds.hidden = h\n",
    "out,h2 = ds(\"Good god\")\n",
    "print out[1].data.topk(1)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
